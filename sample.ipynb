{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d339b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<openai.OpenAI object at 0x73cbdf710c20>\n",
      "Hello from your Jupyter notebook! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "with open(\"openai_key.txt\") as f:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = f.read().strip()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(client)\n",
    "\n",
    "# âœ… Confirm your OpenAI client works\n",
    "from openai import OpenAI\n",
    "\n",
    "# assuming your client variable is already set like this:\n",
    "# client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # fast + low-cost model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Say hello from my Jupyter notebook!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44946c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Embrace the journey of learning AI, for every line of code unlocks a world of possibilities. Let curiosity guide you, and innovation will follow.\"\n"
     ]
    }
   ],
   "source": [
    "# Make a test API call\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # small, fast, cost-efficient model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a 2-line motivational quote about learning AI.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the model's output\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd6fbe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) is revolutionizing various industries through task automation, enhanced decision-making, and new capabilities like language understanding and image recognition, while also posing challenges related to bias, transparency, and ethical issues.\n"
     ]
    }
   ],
   "source": [
    "text_to_summarize = \"\"\"\n",
    "Artificial Intelligence (AI) is transforming industries by automating tasks,\n",
    "improving decision-making, and enabling new capabilities such as language understanding\n",
    "and image recognition. However, it also brings challenges like bias, transparency,\n",
    "and ethical considerations.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a summarization assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize the following text in one short paragraph:\\n\\n{text_to_summarize}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c9eb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "content=\"Hello! It's great to hear from you! How can I assist you today with LangChain or anything else?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 12, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CaLXSRtJ9oL3se510WrccIeyWSKOe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--dd303ab1-48c9-47ec-abd1-cb410f015c27-0' usage_metadata={'input_tokens': 12, 'output_tokens': 22, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "\n",
    "with open(\"openai_key.txt\") as f:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = f.read().strip()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "with open(\"langchain_key.txt\") as f:\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = f.read().strip()\n",
    "print(os.environ[\"LANGCHAIN_API_KEY\"])\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "print(chat.invoke(\"Hello from LangChain!\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
